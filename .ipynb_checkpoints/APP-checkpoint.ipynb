{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc54ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import contextlib\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "342c88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras.layers import *\n",
    "from funciones import *\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea9f635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nodulos=pd.read_csv(\"nodulos_descripcion110.csv\",header=0,index_col=0)\n",
    "df_nodulos.columns=[\"Forma\",\"Margen\",\"Orientación\",\"Ecogenicidad\",\"Característica Posterior\",\"Halo Ecogénico\", 'Sugestivo', 'Forma2',\n",
    "       'Margen2', 'Orientación2', 'Ecogenicidad2', 'Característica Posterior2',\n",
    "       'Halo Ecogénico2', 'Sugestivo2', 'BIRADS', 'Resultados', 'Num Nódulos']\n",
    "df_nodulos[\"Ecogenicidad\"].replace({\"compleja\": \"heterogénea\", \"mixta\":\"heterogénea\"}, inplace=True)\n",
    "df_nodulos[\"Ecogenicidad2\"].replace({\"compleja\": \"heterogénea\", \"mixta\":\"heterogénea\"}, inplace=True)\n",
    "\n",
    "\n",
    "Formas=[l for l in list(set(list(df_nodulos[\"Forma\"])+list(df_nodulos[\"Forma2\"]))) if l==l]\n",
    "Margenes=[l for l in list(set(list(df_nodulos[\"Margen\"])+list(df_nodulos[\"Margen2\"]))) if l==l]\n",
    "Orientaciones=[\"paralela\",\"antiparalela\"]\n",
    "Ecogenicidades=[l for l in list(set(list(df_nodulos[\"Ecogenicidad\"])+list(df_nodulos[\"Ecogenicidad2\"]))) if l==l]\n",
    "Ecogenicidades.remove(\"hiperecoica\")\n",
    "Posteriores=[\"sin cambios\",\"refuerzo\",\"sombra\",\"mixto\"]\n",
    "Posteriores.remove(\"mixto\")\n",
    "Halos=[\"sí\",\"no\"]\n",
    "Sugestividades=[l for l in list(set(list(df_nodulos[\"Sugestivo\"])+list(df_nodulos[\"Sugestivo2\"]))) if l==l]\n",
    "Sugestividades2=[l for l in list(set(list(df_nodulos[\"Sugestivo\"])+list(df_nodulos[\"Sugestivo2\"]))) if l==l]\n",
    "Sugestividades2.append(\"otro\")\n",
    "Sugestividades.remove(\"ganglio intramamario\")\n",
    "Sugestividades.remove(\"fibroadenoma con degeneración quística\")\n",
    "Sugestividades.remove(\"quiste tóxico\")\n",
    "Sugestividades.remove(\"lesión papilar intraquística\")\n",
    "Sugestividades2.remove(\"ganglio intramamario\")\n",
    "Sugestividades2.remove(\"fibroadenoma con degeneración quística\")\n",
    "Sugestividades2.remove(\"quiste tóxico\")\n",
    "Sugestividades2.remove(\"lesión papilar intraquística\")\n",
    "#BIRADS=[\"2\",\"3\",\"4A\",\"4B\",\"4C\",\"5\"]\n",
    "Resultados=[\"benign\",\"malignant\"]\n",
    "#Tipo=[\"quiste\",\"fibroadenoma\",\"carcinoma ductal invasivo\",\"carcinoma ductal in situ\",\"linfoma\"]\n",
    "#voc=set(Formas+Margenes+Orientaciones+Ecogenicidades+Posteriores+Halos+Sugestividades+BIRADS+Resultados)\n",
    "\n",
    "voc2=set(Formas+Margenes+Orientaciones+Ecogenicidades+Posteriores+Halos+Sugestividades2+Resultados)\n",
    "voc2=list(voc2)\n",
    "voc2.sort()\n",
    "\n",
    "Formas.sort()\n",
    "Margenes.sort()\n",
    "Ecogenicidades.sort()\n",
    "Orientaciones.sort()\n",
    "Posteriores.sort()\n",
    "Halos.sort()\n",
    "Sugestividades.sort()\n",
    "Sugestividades2.sort()\n",
    "Resultados.sort()\n",
    "\n",
    "BIRADS=[\"2\",\"3\",\"4A\",\"4B\",\"4C\",\"5\"]\n",
    "BIRADS.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcfbb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx_formas = dict((word, idx) for idx, word in enumerate(Formas))\n",
    "idx_to_word_formas = dict((idx, word) for idx, word in enumerate(Formas))\n",
    "\n",
    "word_to_idx_margenes = dict((word, idx) for idx, word in enumerate(Margenes))\n",
    "idx_to_word_margenes = dict((idx, word) for idx, word in enumerate(Margenes))\n",
    "\n",
    "word_to_idx_orientaciones = dict((word, idx) for idx, word in enumerate(Orientaciones))\n",
    "idx_to_word_orientaciones = dict((idx, word) for idx, word in enumerate(Orientaciones))\n",
    "\n",
    "word_to_idx_ecogenicidades = dict((word, idx) for idx, word in enumerate(Ecogenicidades))\n",
    "idx_to_word_ecogenicidades = dict((idx, word) for idx, word in enumerate(Ecogenicidades))\n",
    "\n",
    "word_to_idx_posteriores = dict((word, idx) for idx, word in enumerate(Posteriores))\n",
    "idx_to_word_posteriores = dict((idx, word) for idx, word in enumerate(Posteriores))\n",
    "\n",
    "word_to_idx_halos = dict((word, idx) for idx, word in enumerate(Halos))\n",
    "idx_to_word_halos = dict((idx, word) for idx, word in enumerate(Halos))\n",
    "\n",
    "word_to_idx_sugestividades = dict((word, idx) for idx, word in enumerate(Sugestividades))\n",
    "idx_to_word_sugestividades = dict((idx, word) for idx, word in enumerate(Sugestividades))\n",
    "\n",
    "word_to_idx_sugestividades2 = dict((word, idx) for idx, word in enumerate(Sugestividades2))\n",
    "idx_to_word_sugestividades2 = dict((idx, word) for idx, word in enumerate(Sugestividades2))\n",
    "\n",
    "word_to_idx_resultados = dict((word, idx) for idx, word in enumerate(Resultados))\n",
    "idx_to_word_resultados = dict((idx, word) for idx, word in enumerate(Resultados))\n",
    "\n",
    "word_to_idx_birads = dict((word, idx) for idx, word in enumerate(BIRADS))\n",
    "idx_to_word_birads = dict((idx, word) for idx, word in enumerate(BIRADS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Horizontal_flip(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Horizontal_flip, self).__init__()\n",
    "        super(Horizontal_flip, self).__init__(**kwargs)\n",
    "    def call(self,inputs,training=None):\n",
    "        if not training:\n",
    "            output=inputs\n",
    "        else:\n",
    "            output=tf.image.random_flip_left_right(inputs)\n",
    "        return output\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "273a42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, dropout=False, L2Attention=False, Gatted=False, L2dim=20,name=\"Attention\",**kwargs):\n",
    "        #Inicializa los features que no dependen de la entrada\n",
    "        self.L2Attention=L2Attention\n",
    "        self.Gatted=Gatted\n",
    "        self.L2dim=L2dim\n",
    "        self.weight_initializer = tf.keras.initializers.glorot_normal\n",
    "        self.const_initializer = tf.keras.initializers.Zeros()\n",
    "        self.dropout=dropout\n",
    "        \n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        Features_shape=input_shape\n",
    "        F_1=Features_shape[1]\n",
    "        F_2=Features_shape[2]\n",
    "        #Inicia los features que dependen de la entrada\n",
    "        \n",
    "        #Iniciar pesos  Atención\n",
    "        if self.L2Attention or self.Gatted:\n",
    "            self.w_a_1= self.add_weight(\"w_a_1\", shape=[F_2,self.L2dim])\n",
    "            self.b_a_1=self.add_weight(\"b_a_1\",shape=[self.L2dim])\n",
    "            \n",
    "            self.w_a_2= self.add_weight(\"w_a_2\", shape=[self.L2dim,1])\n",
    "            self.b_a_2=self.add_weight(\"b_a_2\",shape=[1])\n",
    "            \n",
    "            if self.Gatted:\n",
    "                self.w_a_g= self.add_weight(\"w_a_g\", shape=[F_2,self.L2dim])\n",
    "                self.b_a_g=self.add_weight(\"b_a_g\",shape=[self.L2dim])\n",
    "             \n",
    "        else:\n",
    "            self.w_a= self.add_weight(\"w_a\", shape=[F_2,1])\n",
    "            self.b_a=self.add_weight(\"b_a\",shape=[1])\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        #Crear primer estado oculto y memoria\n",
    "        input_data=inputs\n",
    "\n",
    "        #Primear atención\n",
    "        #lstm\n",
    "        if self.L2Attention or self.Gatted:\n",
    "            Attention1=tf.nn.tanh(reshape_matmul(input_data,self.w_a_1)+self.b_a_1) #(B,F_1,L2dim)\n",
    "\n",
    "            if self.Gatted:\n",
    "                Attention2=k.activations.sigmoid(reshape_matmul(input_data,self.w_a_g)+self.b_a_g) #(B,F_1,L2dim)\n",
    "                Attention1=tf.math.multiply(Attention1,Attention2)\n",
    "            Attention=reshape_matmul(Attention1,self.w_a_2)+self.b_a_2 #(B,F_1,1)\n",
    "        else:\n",
    "            Attention=tf.nn.tanh(reshape_matmul(input_data,self.w_a)+self.b_a) #(B,F_1,1)\n",
    "\n",
    "        if self.dropout and False:\n",
    "            alfa=tf.nn.softmax(tf.nn.dropout(Attention[:,:,0],0.5))\n",
    "        else:\n",
    "            alfa=tf.nn.softmax(Attention[:,:,0]) #(B,F_1)\n",
    "        context = tf.reduce_sum(tf.math.multiply(input_data, tf.expand_dims(alfa, axis=2)), 1) #(B,F_2)\n",
    "        if self.dropout and training:\n",
    "            context=tf.nn.dropout(context,0.5)\n",
    "                                                                                        \n",
    "        return context, alfa\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Attention, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a18bfeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_14 (InputLayer)        [(None, 450, 450, 1)]     0         \n",
      "_________________________________________________________________\n",
      "model_20 (Functional)        (None, 196, 512)          7637342   \n",
      "_________________________________________________________________\n",
      "attention (Attention)        ((None, 512), (None, 196) 513       \n",
      "_________________________________________________________________\n",
      "model_1 (Functional)         [(None, 4), (None, 4), (N 12947     \n",
      "=================================================================\n",
      "Total params: 7,650,802\n",
      "Trainable params: 2,374,322\n",
      "Non-trainable params: 5,276,480\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "Encoder = k.models.load_model('EncoderYOLOSAtt2.h5',custom_objects={\"Horizontal_flip\":Horizontal_flip})\n",
    "Dense_model=k.models.load_model(\"DecoderDenseYOLOSAtt2.h5\")\n",
    "Attention_layer=Attention()\n",
    "\n",
    "\n",
    "inputs=Encoder.inputs\n",
    "features=Encoder(inputs)\n",
    "context,alfa=Attention_layer(features)\n",
    "outputs=Dense_model(context)\n",
    "\n",
    "Inference_model=k.Model(inputs=inputs,outputs=outputs)\n",
    "print(Inference_model.summary())\n",
    "\n",
    "with open(\"YOLO_SAtt_weights_3Channel22.pkl\", \"rb\") as open_file:\n",
    "    LSTM_list = pickle.load(open_file)\n",
    "\n",
    "    \n",
    "Attention_layer.set_weights(LSTM_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b892f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Birads_simple=k.models.load_model(\"MLP_simple2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12377648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(words,enc_m,dec_m):\n",
    "    len_frase=len(words)\n",
    "    boolean=False\n",
    "    boolean2=False\n",
    "    i_sug=0\n",
    "    caption=\"\"\n",
    "    for i,word in enumerate(words):\n",
    "        frase=\"\"\n",
    "        if word==\"/n\":\n",
    "            continue\n",
    "        elif word in Formas:\n",
    "            if word!=\"irregular\":\n",
    "                frase=word[:-1]+\"o\"\n",
    "            else:\n",
    "                frase+=word\n",
    "        elif word in Margenes:\n",
    "            frase=word\n",
    "        elif word in Orientaciones:\n",
    "            frase=\"con orientación \"+word\n",
    "        elif word in Ecogenicidades:\n",
    "            if word==\"compleja\":\n",
    "                frase=\"con ecogenicidad compleja\"\n",
    "            elif word==\"mixta\":\n",
    "                frase=\"con ecogenicidad mixta\"\n",
    "            else:\n",
    "                frase=word[:-1]+\"o\"\n",
    "        elif word in Posteriores:\n",
    "            if word==\"mixto\":\n",
    "                frase=\"con característica posterior mixta\"\n",
    "            elif word==\"sin cambios\":\n",
    "                frase=\"sin cambios posteriores\"\n",
    "            else:\n",
    "                frase=\"con \"+word+ \" posterior\"\n",
    "        elif word in Halos:\n",
    "            if word==\"no\":\n",
    "                frase=\"sin halo ecogénico\"\n",
    "            elif word==\"sí\":\n",
    "                frase=\"con halo ecogénico\"\n",
    "        elif word in Sugestividades:\n",
    "            frase=\"sugestivo de \"+ word\n",
    "            boolean=True\n",
    "            i_sug=i\n",
    "        elif word in BIRADS:\n",
    "            if boolean:\n",
    "                frase=\" (BIRADS® \"+word+\")\"\n",
    "            else:\n",
    "                i_sug=i\n",
    "                if word==\"2\":\n",
    "                    frase=\" (BIRADS® \"+word+\")\"\n",
    "                if word==\"3\":\n",
    "                    frase=\"probablemente benigno \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"4A\":\n",
    "                    frase=\"de baja sospecha \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"4B\":\n",
    "                    frase=\"de sospecha intermedia \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"4C\":\n",
    "                    frase=\"de alta sospecha \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"5\":\n",
    "                    frase=\"sugestivo de carcinoma \"+\"(BIRADS® \"+word+\")\"\n",
    "        else:\n",
    "            if not boolean2:\n",
    "                frase=\". Resultado final aprendido por base de datos: \"\n",
    "                boolean2=True\n",
    "            if word in Resultados:\n",
    "                if word==\"benign\":\n",
    "                    frase+=\"benigno\"\n",
    "                else:\n",
    "                    frase+=\"maligno\"\n",
    "#            elif word in Tipo:\n",
    "#                frase+=word\n",
    "        if frase!=\"\":\n",
    "            if i==0:\n",
    "                caption+=\"Nódulo \"+frase\n",
    "            elif word in Ecogenicidades:\n",
    "                if word[:2]==\"hi\" or word[0]==\"i\":\n",
    "                    caption+=\" e \"+frase\n",
    "                else:\n",
    "                    caption+=\" y \"+frase\n",
    "            elif i==0:\n",
    "                caption+=\"Nódulo \"+frase\n",
    "            elif frase[0]==\".\" or frase[:2]==\" (\":\n",
    "                caption+=frase\n",
    "            elif caption[-2:]==\": \":\n",
    "                caption+=frase\n",
    "            elif i==len(frase)-1:\n",
    "                caption+=\", \"+frase+\".\"\n",
    "            else:\n",
    "                caption+=\", \" +frase\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7287cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_simple(imag,model):\n",
    "    result=model(np.reshape(imag,(1,450,450,1)))\n",
    "    result=[result[1],result[3],result[4],result[0],result[5],result[2],result[7],result[6]]\n",
    "    output_ejemplo=[]\n",
    "    t=0\n",
    "    oval_bool=False\n",
    "    redondeada_bool=False\n",
    "    threshold=0\n",
    "    total=[]\n",
    "    for carac in result:\n",
    "        maxi=np.max(carac)\n",
    "        mask=maxi>threshold\n",
    "        result_carac=np.argmax(carac)+1\n",
    "        final=result_carac*mask\n",
    "        if t==0:\n",
    "            m=np.zeros(len(Formas))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_formas[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "                if word==\"ovalada\":\n",
    "                    oval_bool=True\n",
    "                elif word==\"redondeada\":\n",
    "                    redondeada_bool=True\n",
    "            total.append(m)\n",
    "        if t==1:\n",
    "            m=np.zeros(len(Margenes))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_margenes[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==2:\n",
    "            m=np.zeros(len(Orientaciones))\n",
    "            if maxi>0.45:\n",
    "                m[final-1]=1\n",
    "                if oval_bool:\n",
    "                    output_ejemplo.append(\"paralela\")\n",
    "                elif redondeada_bool:\n",
    "                    t=t+1\n",
    "                    continue\n",
    "                else:\n",
    "                    word=idx_to_word_orientaciones[final-1]\n",
    "                    output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==3:\n",
    "            m=np.zeros(len(Ecogenicidades))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_ecogenicidades[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==4:\n",
    "            m=np.zeros(len(Posteriores))\n",
    "            if maxi>0.3:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_posteriores[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==5:\n",
    "            m=np.zeros(len(Halos))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_halos[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==6:\n",
    "            m=np.zeros(len(Sugestividades2))\n",
    "            if maxi>0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_sugestividades2[final-1]\n",
    "                if word!=\"otro\":\n",
    "                    output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==7:\n",
    "            m=np.zeros(len(Resultados))\n",
    "            if final!=0:\n",
    "                word=idx_to_word_resultados[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        t=t+1\n",
    "    # output_ejemplo=[output_ejemplo[1],output_ejemplo[3],output_ejemplo[0],\n",
    "    #                     output_ejemplo[4],output_ejemplo[5],output_ejemplo[2],output_ejemplo[7],output_ejemplo[6]]\n",
    "\n",
    "    total=np.concatenate(total)\n",
    "    if \"espiculado\" in output_ejemplo:\n",
    "        birads=\"5\"\n",
    "    if \"quiste simple\" in output_ejemplo:\n",
    "        birads=\"2\"\n",
    "    elif \"quiste complejo\" in output_ejemplo:\n",
    "        birads=\"4A\"\n",
    "    # elif \"fibroadenoma\" in desc:\n",
    "    #     BIRADS_out[key]=\"3\"\n",
    "    else:\n",
    "        birads=idx_to_word_birads[np.argmax(Birads_simple(total.reshape((1,len(voc2)))))]\n",
    "    output_ejemplo=output_ejemplo[:-1]+[birads]+[output_ejemplo[-1]]\n",
    "    frase=generate_caption(output_ejemplo,1,2)\n",
    "    \n",
    "    return(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "969aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamaño=450\n",
    "def results(imagen,imagen_dir=\"..\\YOLO_para_describir\\images\"):\n",
    "    imag_dir=os.path.join(imagen_dir,imagen)\n",
    "    \n",
    "    if not glob.glob(os.path.join(\"runs/detect/Yolo_test_lstm\",imagen)):\n",
    "        !python detect.py --weights YOLO_total.pt --conf 0.25 --hide-labels --source {imag_dir} --data data/YOLO.yaml --exist-ok --name Yolo_test_lstm --save-crop\n",
    "    original=load_img(os.path.join(\"runs/detect/Yolo_test_lstm\",imagen),color_mode=\"grayscale\")\n",
    "    \n",
    "    nodulos=glob.glob(os.path.join(\"runs/detect/Yolo_test_lstm/crops/nodulo\",imagen[:-4]+\"_*\"))\n",
    "    print(\"Número de nódulos: \",len(nodulos))\n",
    "    plt.imshow(original,cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    i=1\n",
    "    for ima in nodulos:\n",
    "        if i==1:\n",
    "            imag=load_img(ima,color_mode=\"grayscale\")\n",
    "        else:\n",
    "            imag=load_img(ima,color_mode=\"grayscale\")\n",
    "        ancho,largo=imag.size\n",
    "        \n",
    "        plt.imshow(imag,cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        if ancho>450 or largo>450:\n",
    "            ratio=ancho/largo\n",
    "            if ratio>1:\n",
    "                imag=imag.resize((450,int(450/ratio)))\n",
    "\n",
    "            else:\n",
    "                imag=imag.resize((int(450*ratio),450))\n",
    "            ancho,largo=imag.size\n",
    "        imag=img_to_array(imag)/255.\n",
    "        imag=tf.image.pad_to_bounding_box(\n",
    "        imag, (tamaño-largo)//2,(tamaño-ancho)//2, 450, 450\n",
    "        )\n",
    "        imag=img_to_array(imag)\n",
    "        words=results_simple(imag,Inference_model)\n",
    "        \n",
    "        print(\"DESCRIPCIÓN:\\n\",words+\".\")\n",
    "        #print(\"Oval, circumscribed, isoechoic mass, with parallel orientation and no echogenic halo.\\nSuggestive of fibroadenoma. BIRADS® 3. Result predicted from dataset labels: benign.\")\n",
    "#         print(\"Irregular, spiculated, hipoechoic mass, with posterior shadowing, antiparallel orientation and echogenic halo.\\nBIRADS® 5. Result predicted from dataset labels: malignant.\")\n",
    "        #visualize(imagen=imag,alfas=np.array(alfas[:,0]))\n",
    "        i=i+1\n",
    "    if not nodulos:\n",
    "        print(\"Sin hallazgos. (BIRADS® 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6caaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.redirect_stdout(None):\n",
    "    %cd yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46e548",
   "metadata": {},
   "source": [
    "# Esto es una prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4f98237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e2ada9350ce429ebb77ca1a06e0ca89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Selecciona una ecografía'), FileUpload(value={}, description='Upload'), Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "out_pl=widgets.Output()\n",
    "btn_run = widgets.Button(description='Descripción')\n",
    "lbl_pred = widgets.Label()\n",
    "def on_click_descripcion(change):\n",
    "    img=Image.open(io.BytesIO(btn_upload.data[-1]))\n",
    "    name=list(btn_upload.value.keys())[-1]\n",
    "    if \" \" in name:\n",
    "        name=\"\".join(name.split(\" \"))\n",
    "    img_dir=os.path.join(\"../Imagenes_detect\",name)\n",
    "    img.save(img_dir)\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: \n",
    "        display(img)\n",
    "        words=results(name,\"../Imagenes_detect\")\n",
    "btn_run.on_click(on_click_descripcion)\n",
    "VBox([widgets.Label('Selecciona una ecografía'), \n",
    "      btn_upload, btn_run, out_pl])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO_tf",
   "language": "python",
   "name": "yolo_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
