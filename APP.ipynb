{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc54ee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import contextlib\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import VBox\n",
    "import io\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "342c88b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras as k\n",
    "from tensorflow.keras.layers import *\n",
    "from funciones import *\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea9f635c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'nodulos_descripcion110.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12844\\1509797287.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_nodulos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nodulos_descripcion110.csv\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m df_nodulos.columns=[\"Forma\",\"Margen\",\"Orientación\",\"Ecogenicidad\",\"Característica Posterior\",\"Halo Ecogénico\", 'Sugestivo', 'Forma2',\n\u001b[0;32m      3\u001b[0m        \u001b[1;34m'Margen2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Orientación2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Ecogenicidad2'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Característica Posterior2'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m        'Halo Ecogénico2', 'Sugestivo2', 'BIRADS', 'Resultados', 'Num Nódulos']\n\u001b[0;32m      5\u001b[0m \u001b[0mdf_nodulos\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Ecogenicidad\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"compleja\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m\"heterogénea\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"mixta\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m\"heterogénea\"\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    813\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1038\u001b[0m             )\n\u001b[0;32m   1039\u001b[0m         \u001b[1;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1040\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1041\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[1;31m# open handles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 51\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     52\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\parsers\\base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[1;34m(self, src, kwds)\u001b[0m\n\u001b[0;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"memory_map\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"storage_options\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m             \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"encoding_errors\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"strict\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    230\u001b[0m         )\n\u001b[0;32m    231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 707\u001b[1;33m                 \u001b[0mnewline\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    708\u001b[0m             )\n\u001b[0;32m    709\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'nodulos_descripcion110.csv'"
     ]
    }
   ],
   "source": [
    "df_nodulos=pd.read_csv(\"nodulos_descripcion110.csv\",header=0,index_col=0)\n",
    "df_nodulos.columns=[\"Forma\",\"Margen\",\"Orientación\",\"Ecogenicidad\",\"Característica Posterior\",\"Halo Ecogénico\", 'Sugestivo', 'Forma2',\n",
    "       'Margen2', 'Orientación2', 'Ecogenicidad2', 'Característica Posterior2',\n",
    "       'Halo Ecogénico2', 'Sugestivo2', 'BIRADS', 'Resultados', 'Num Nódulos']\n",
    "df_nodulos[\"Ecogenicidad\"].replace({\"compleja\": \"heterogénea\", \"mixta\":\"heterogénea\"}, inplace=True)\n",
    "df_nodulos[\"Ecogenicidad2\"].replace({\"compleja\": \"heterogénea\", \"mixta\":\"heterogénea\"}, inplace=True)\n",
    "\n",
    "\n",
    "Formas=[l for l in list(set(list(df_nodulos[\"Forma\"])+list(df_nodulos[\"Forma2\"]))) if l==l]\n",
    "Margenes=[l for l in list(set(list(df_nodulos[\"Margen\"])+list(df_nodulos[\"Margen2\"]))) if l==l]\n",
    "Orientaciones=[\"paralela\",\"antiparalela\"]\n",
    "Ecogenicidades=[l for l in list(set(list(df_nodulos[\"Ecogenicidad\"])+list(df_nodulos[\"Ecogenicidad2\"]))) if l==l]\n",
    "Ecogenicidades.remove(\"hiperecoica\")\n",
    "Posteriores=[\"sin cambios\",\"refuerzo\",\"sombra\",\"mixto\"]\n",
    "Posteriores.remove(\"mixto\")\n",
    "Halos=[\"sí\",\"no\"]\n",
    "Sugestividades=[l for l in list(set(list(df_nodulos[\"Sugestivo\"])+list(df_nodulos[\"Sugestivo2\"]))) if l==l]\n",
    "Sugestividades2=[l for l in list(set(list(df_nodulos[\"Sugestivo\"])+list(df_nodulos[\"Sugestivo2\"]))) if l==l]\n",
    "Sugestividades2.append(\"otro\")\n",
    "Sugestividades.remove(\"ganglio intramamario\")\n",
    "Sugestividades.remove(\"fibroadenoma con degeneración quística\")\n",
    "Sugestividades.remove(\"quiste tóxico\")\n",
    "Sugestividades.remove(\"lesión papilar intraquística\")\n",
    "Sugestividades2.remove(\"ganglio intramamario\")\n",
    "Sugestividades2.remove(\"fibroadenoma con degeneración quística\")\n",
    "Sugestividades2.remove(\"quiste tóxico\")\n",
    "Sugestividades2.remove(\"lesión papilar intraquística\")\n",
    "#BIRADS=[\"2\",\"3\",\"4A\",\"4B\",\"4C\",\"5\"]\n",
    "Resultados=[\"benign\",\"malignant\"]\n",
    "#Tipo=[\"quiste\",\"fibroadenoma\",\"carcinoma ductal invasivo\",\"carcinoma ductal in situ\",\"linfoma\"]\n",
    "#voc=set(Formas+Margenes+Orientaciones+Ecogenicidades+Posteriores+Halos+Sugestividades+BIRADS+Resultados)\n",
    "\n",
    "voc2=set(Formas+Margenes+Orientaciones+Ecogenicidades+Posteriores+Halos+Sugestividades2+Resultados)\n",
    "voc2=list(voc2)\n",
    "voc2.sort()\n",
    "\n",
    "Formas.sort()\n",
    "Margenes.sort()\n",
    "Ecogenicidades.sort()\n",
    "Orientaciones.sort()\n",
    "Posteriores.sort()\n",
    "Halos.sort()\n",
    "Sugestividades.sort()\n",
    "Sugestividades2.sort()\n",
    "Resultados.sort()\n",
    "\n",
    "BIRADS=[\"2\",\"3\",\"4A\",\"4B\",\"4C\",\"5\"]\n",
    "BIRADS.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bcfbb1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_idx_formas = dict((word, idx) for idx, word in enumerate(Formas))\n",
    "idx_to_word_formas = dict((idx, word) for idx, word in enumerate(Formas))\n",
    "\n",
    "word_to_idx_margenes = dict((word, idx) for idx, word in enumerate(Margenes))\n",
    "idx_to_word_margenes = dict((idx, word) for idx, word in enumerate(Margenes))\n",
    "\n",
    "word_to_idx_orientaciones = dict((word, idx) for idx, word in enumerate(Orientaciones))\n",
    "idx_to_word_orientaciones = dict((idx, word) for idx, word in enumerate(Orientaciones))\n",
    "\n",
    "word_to_idx_ecogenicidades = dict((word, idx) for idx, word in enumerate(Ecogenicidades))\n",
    "idx_to_word_ecogenicidades = dict((idx, word) for idx, word in enumerate(Ecogenicidades))\n",
    "\n",
    "word_to_idx_posteriores = dict((word, idx) for idx, word in enumerate(Posteriores))\n",
    "idx_to_word_posteriores = dict((idx, word) for idx, word in enumerate(Posteriores))\n",
    "\n",
    "word_to_idx_halos = dict((word, idx) for idx, word in enumerate(Halos))\n",
    "idx_to_word_halos = dict((idx, word) for idx, word in enumerate(Halos))\n",
    "\n",
    "word_to_idx_sugestividades = dict((word, idx) for idx, word in enumerate(Sugestividades))\n",
    "idx_to_word_sugestividades = dict((idx, word) for idx, word in enumerate(Sugestividades))\n",
    "\n",
    "word_to_idx_sugestividades2 = dict((word, idx) for idx, word in enumerate(Sugestividades2))\n",
    "idx_to_word_sugestividades2 = dict((idx, word) for idx, word in enumerate(Sugestividades2))\n",
    "\n",
    "word_to_idx_resultados = dict((word, idx) for idx, word in enumerate(Resultados))\n",
    "idx_to_word_resultados = dict((idx, word) for idx, word in enumerate(Resultados))\n",
    "\n",
    "word_to_idx_birads = dict((word, idx) for idx, word in enumerate(BIRADS))\n",
    "idx_to_word_birads = dict((idx, word) for idx, word in enumerate(BIRADS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3da955b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Horizontal_flip(Layer):\n",
    "    def __init__(self,**kwargs):\n",
    "        super(Horizontal_flip, self).__init__()\n",
    "        super(Horizontal_flip, self).__init__(**kwargs)\n",
    "    def call(self,inputs,training=None):\n",
    "        if not training:\n",
    "            output=inputs\n",
    "        else:\n",
    "            output=tf.image.random_flip_left_right(inputs)\n",
    "        return output\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "273a42f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(Layer):\n",
    "    def __init__(self, dropout=False, L2Attention=False, Gatted=False, L2dim=20,name=\"Attention\",**kwargs):\n",
    "        #Inicializa los features que no dependen de la entrada\n",
    "        self.L2Attention=L2Attention\n",
    "        self.Gatted=Gatted\n",
    "        self.L2dim=L2dim\n",
    "        self.weight_initializer = tf.keras.initializers.glorot_normal\n",
    "        self.const_initializer = tf.keras.initializers.Zeros()\n",
    "        self.dropout=dropout\n",
    "        \n",
    "\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "        \n",
    "    def build(self,input_shape):\n",
    "        Features_shape=input_shape\n",
    "        F_1=Features_shape[1]\n",
    "        F_2=Features_shape[2]\n",
    "        #Inicia los features que dependen de la entrada\n",
    "        \n",
    "        #Iniciar pesos  Atención\n",
    "        if self.L2Attention or self.Gatted:\n",
    "            self.w_a_1= self.add_weight(\"w_a_1\", shape=[F_2,self.L2dim])\n",
    "            self.b_a_1=self.add_weight(\"b_a_1\",shape=[self.L2dim])\n",
    "            \n",
    "            self.w_a_2= self.add_weight(\"w_a_2\", shape=[self.L2dim,1])\n",
    "            self.b_a_2=self.add_weight(\"b_a_2\",shape=[1])\n",
    "            \n",
    "            if self.Gatted:\n",
    "                self.w_a_g= self.add_weight(\"w_a_g\", shape=[F_2,self.L2dim])\n",
    "                self.b_a_g=self.add_weight(\"b_a_g\",shape=[self.L2dim])\n",
    "             \n",
    "        else:\n",
    "            self.w_a= self.add_weight(\"w_a\", shape=[F_2,1])\n",
    "            self.b_a=self.add_weight(\"b_a\",shape=[1])\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        #Crear primer estado oculto y memoria\n",
    "        input_data=inputs\n",
    "\n",
    "        #Primear atención\n",
    "        #lstm\n",
    "        if self.L2Attention or self.Gatted:\n",
    "            Attention1=tf.nn.tanh(reshape_matmul(input_data,self.w_a_1)+self.b_a_1) #(B,F_1,L2dim)\n",
    "\n",
    "            if self.Gatted:\n",
    "                Attention2=k.activations.sigmoid(reshape_matmul(input_data,self.w_a_g)+self.b_a_g) #(B,F_1,L2dim)\n",
    "                Attention1=tf.math.multiply(Attention1,Attention2)\n",
    "            Attention=reshape_matmul(Attention1,self.w_a_2)+self.b_a_2 #(B,F_1,1)\n",
    "        else:\n",
    "            Attention=tf.nn.tanh(reshape_matmul(input_data,self.w_a)+self.b_a) #(B,F_1,1)\n",
    "\n",
    "        if self.dropout and False:\n",
    "            alfa=tf.nn.softmax(tf.nn.dropout(Attention[:,:,0],0.5))\n",
    "        else:\n",
    "            alfa=tf.nn.softmax(Attention[:,:,0]) #(B,F_1)\n",
    "        context = tf.reduce_sum(tf.math.multiply(input_data, tf.expand_dims(alfa, axis=2)), 1) #(B,F_2)\n",
    "        if self.dropout and training:\n",
    "            context=tf.nn.dropout(context,0.5)\n",
    "                                                                                        \n",
    "        return context, alfa\n",
    "    \n",
    "    def get_config(self):\n",
    "        config = super(Attention, self).get_config()\n",
    "        return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a18bfeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: EncoderYOLOSAtt2.h5\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12844\\854186318.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mEncoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'EncoderYOLOSAtt2.h5'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m\"Horizontal_flip\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mHorizontal_flip\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mDense_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"DecoderDenseYOLOSAtt2.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mAttention_layer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m   raise IOError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[1;32m--> 121\u001b[1;33m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: EncoderYOLOSAtt2.h5\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "Encoder = k.models.load_model('EncoderYOLOSAtt2.h5',custom_objects={\"Horizontal_flip\":Horizontal_flip})\n",
    "Dense_model=k.models.load_model(\"DecoderDenseYOLOSAtt2.h5\")\n",
    "Attention_layer=Attention()\n",
    "\n",
    "\n",
    "inputs=Encoder.inputs\n",
    "features=Encoder(inputs)\n",
    "context,alfa=Attention_layer(features)\n",
    "outputs=Dense_model(context)\n",
    "\n",
    "Inference_model=k.Model(inputs=inputs,outputs=outputs)\n",
    "print(Inference_model.summary())\n",
    "\n",
    "with open(\"YOLO_SAtt_weights_3Channel22.pkl\", \"rb\") as open_file:\n",
    "    LSTM_list = pickle.load(open_file)\n",
    "\n",
    "    \n",
    "Attention_layer.set_weights(LSTM_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b892f55f",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "SavedModel file does not exist at: MLP_simple2.h5\\{saved_model.pbtxt|saved_model.pb}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12844\\1310277690.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBirads_simple\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MLP_simple2.h5\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\keras\\saving\\save.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    203\u001b[0m         \u001b[0mfilepath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m           \u001b[1;32mreturn\u001b[0m \u001b[0msaved_model_load\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m   raise IOError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\YOLO_tf\\lib\\site-packages\\keras\\saving\\saved_model\\load.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(path, compile, options)\u001b[0m\n\u001b[0;32m    106\u001b[0m   \u001b[1;31m# Look for metadata file or parse the SavedModel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m   \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaved_metadata_pb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSavedMetadata\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 108\u001b[1;33m   \u001b[0mmeta_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__internal__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaved_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_saved_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeta_graphs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    109\u001b[0m   \u001b[0mobject_graph_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmeta_graph_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_graph_def\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m   \u001b[0mpath_to_metadata_pb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSAVED_METADATA_PATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\saved_model\\loader_impl.py\u001b[0m in \u001b[0;36mparse_saved_model\u001b[1;34m(export_dir)\u001b[0m\n\u001b[0;32m    119\u001b[0m         \u001b[1;34m\"SavedModel file does not exist at: %s%s{%s|%s}\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         (export_dir, os.path.sep, constants.SAVED_MODEL_FILENAME_PBTXT,\n\u001b[1;32m--> 121\u001b[1;33m          constants.SAVED_MODEL_FILENAME_PB))\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: SavedModel file does not exist at: MLP_simple2.h5\\{saved_model.pbtxt|saved_model.pb}"
     ]
    }
   ],
   "source": [
    "Birads_simple=k.models.load_model(\"MLP_simple2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12377648",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_caption(words,enc_m,dec_m):\n",
    "    len_frase=len(words)\n",
    "    boolean=False\n",
    "    boolean2=False\n",
    "    i_sug=0\n",
    "    caption=\"\"\n",
    "    for i,word in enumerate(words):\n",
    "        frase=\"\"\n",
    "        if word==\"/n\":\n",
    "            continue\n",
    "        elif word in Formas:\n",
    "            if word!=\"irregular\":\n",
    "                frase=word[:-1]+\"o\"\n",
    "            else:\n",
    "                frase+=word\n",
    "        elif word in Margenes:\n",
    "            frase=word\n",
    "        elif word in Orientaciones:\n",
    "            frase=\"con orientación \"+word\n",
    "        elif word in Ecogenicidades:\n",
    "            if word==\"compleja\":\n",
    "                frase=\"con ecogenicidad compleja\"\n",
    "            elif word==\"mixta\":\n",
    "                frase=\"con ecogenicidad mixta\"\n",
    "            else:\n",
    "                frase=word[:-1]+\"o\"\n",
    "        elif word in Posteriores:\n",
    "            if word==\"mixto\":\n",
    "                frase=\"con característica posterior mixta\"\n",
    "            elif word==\"sin cambios\":\n",
    "                frase=\"sin cambios posteriores\"\n",
    "            else:\n",
    "                frase=\"con \"+word+ \" posterior\"\n",
    "        elif word in Halos:\n",
    "            if word==\"no\":\n",
    "                frase=\"sin halo ecogénico\"\n",
    "            elif word==\"sí\":\n",
    "                frase=\"con halo ecogénico\"\n",
    "        elif word in Sugestividades:\n",
    "            frase=\"sugestivo de \"+ word\n",
    "            boolean=True\n",
    "            i_sug=i\n",
    "        elif word in BIRADS:\n",
    "            if boolean:\n",
    "                frase=\" (BIRADS® \"+word+\")\"\n",
    "            else:\n",
    "                i_sug=i\n",
    "                if word==\"2\":\n",
    "                    frase=\" (BIRADS® \"+word+\")\"\n",
    "                if word==\"3\":\n",
    "                    frase=\"probablemente benigno \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"4A\":\n",
    "                    frase=\"de baja sospecha \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"4B\":\n",
    "                    frase=\"de sospecha intermedia \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"4C\":\n",
    "                    frase=\"de alta sospecha \"+\"(BIRADS® \"+word+\")\"\n",
    "                elif word==\"5\":\n",
    "                    frase=\"sugestivo de carcinoma \"+\"(BIRADS® \"+word+\")\"\n",
    "        else:\n",
    "            if not boolean2:\n",
    "                frase=\". Resultado final aprendido por base de datos: \"\n",
    "                boolean2=True\n",
    "            if word in Resultados:\n",
    "                if word==\"benign\":\n",
    "                    frase+=\"benigno\"\n",
    "                else:\n",
    "                    frase+=\"maligno\"\n",
    "#            elif word in Tipo:\n",
    "#                frase+=word\n",
    "        if frase!=\"\":\n",
    "            if i==0:\n",
    "                caption+=\"Nódulo \"+frase\n",
    "            elif word in Ecogenicidades:\n",
    "                if word[:2]==\"hi\" or word[0]==\"i\":\n",
    "                    caption+=\" e \"+frase\n",
    "                else:\n",
    "                    caption+=\" y \"+frase\n",
    "            elif i==0:\n",
    "                caption+=\"Nódulo \"+frase\n",
    "            elif frase[0]==\".\" or frase[:2]==\" (\":\n",
    "                caption+=frase\n",
    "            elif caption[-2:]==\": \":\n",
    "                caption+=frase\n",
    "            elif i==len(frase)-1:\n",
    "                caption+=\", \"+frase+\".\"\n",
    "            else:\n",
    "                caption+=\", \" +frase\n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7287cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_simple(imag,model):\n",
    "    result=model(np.reshape(imag,(1,450,450,1)))\n",
    "    result=[result[1],result[3],result[4],result[0],result[5],result[2],result[7],result[6]]\n",
    "    output_ejemplo=[]\n",
    "    t=0\n",
    "    oval_bool=False\n",
    "    redondeada_bool=False\n",
    "    threshold=0\n",
    "    total=[]\n",
    "    for carac in result:\n",
    "        maxi=np.max(carac)\n",
    "        mask=maxi>threshold\n",
    "        result_carac=np.argmax(carac)+1\n",
    "        final=result_carac*mask\n",
    "        if t==0:\n",
    "            m=np.zeros(len(Formas))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_formas[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "                if word==\"ovalada\":\n",
    "                    oval_bool=True\n",
    "                elif word==\"redondeada\":\n",
    "                    redondeada_bool=True\n",
    "            total.append(m)\n",
    "        if t==1:\n",
    "            m=np.zeros(len(Margenes))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_margenes[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==2:\n",
    "            m=np.zeros(len(Orientaciones))\n",
    "            if maxi>0.45:\n",
    "                m[final-1]=1\n",
    "                if oval_bool:\n",
    "                    output_ejemplo.append(\"paralela\")\n",
    "                elif redondeada_bool:\n",
    "                    t=t+1\n",
    "                    continue\n",
    "                else:\n",
    "                    word=idx_to_word_orientaciones[final-1]\n",
    "                    output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==3:\n",
    "            m=np.zeros(len(Ecogenicidades))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_ecogenicidades[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==4:\n",
    "            m=np.zeros(len(Posteriores))\n",
    "            if maxi>0.3:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_posteriores[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==5:\n",
    "            m=np.zeros(len(Halos))\n",
    "            if final!=0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_halos[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==6:\n",
    "            m=np.zeros(len(Sugestividades2))\n",
    "            if maxi>0:\n",
    "                m[final-1]=1\n",
    "                word=idx_to_word_sugestividades2[final-1]\n",
    "                if word!=\"otro\":\n",
    "                    output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        if t==7:\n",
    "            m=np.zeros(len(Resultados))\n",
    "            if final!=0:\n",
    "                word=idx_to_word_resultados[final-1]\n",
    "                output_ejemplo.append(word)\n",
    "            total.append(m)\n",
    "        t=t+1\n",
    "    # output_ejemplo=[output_ejemplo[1],output_ejemplo[3],output_ejemplo[0],\n",
    "    #                     output_ejemplo[4],output_ejemplo[5],output_ejemplo[2],output_ejemplo[7],output_ejemplo[6]]\n",
    "\n",
    "    total=np.concatenate(total)\n",
    "    if \"espiculado\" in output_ejemplo:\n",
    "        birads=\"5\"\n",
    "    if \"quiste simple\" in output_ejemplo:\n",
    "        birads=\"2\"\n",
    "    elif \"quiste complejo\" in output_ejemplo:\n",
    "        birads=\"4A\"\n",
    "    # elif \"fibroadenoma\" in desc:\n",
    "    #     BIRADS_out[key]=\"3\"\n",
    "    else:\n",
    "        birads=idx_to_word_birads[np.argmax(Birads_simple(total.reshape((1,len(voc2)))))]\n",
    "    output_ejemplo=output_ejemplo[:-1]+[birads]+[output_ejemplo[-1]]\n",
    "    frase=generate_caption(output_ejemplo,1,2)\n",
    "    \n",
    "    return(frase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "969aa384",
   "metadata": {},
   "outputs": [],
   "source": [
    "tamaño=450\n",
    "def results(imagen,imagen_dir=\"..\\YOLO_para_describir\\images\"):\n",
    "    imag_dir=os.path.join(imagen_dir,imagen)\n",
    "    \n",
    "    if not glob.glob(os.path.join(\"runs/detect/Yolo_test_lstm\",imagen)):\n",
    "        !python detect.py --weights YOLO_total.pt --conf 0.25 --hide-labels --source {imag_dir} --data data/YOLO.yaml --exist-ok --name Yolo_test_lstm --save-crop\n",
    "    original=load_img(os.path.join(\"runs/detect/Yolo_test_lstm\",imagen),color_mode=\"grayscale\")\n",
    "    \n",
    "    nodulos=glob.glob(os.path.join(\"runs/detect/Yolo_test_lstm/crops/nodulo\",imagen[:-4]+\"_*\"))\n",
    "    print(\"Número de nódulos: \",len(nodulos))\n",
    "    plt.imshow(original,cmap=\"gray\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    i=1\n",
    "    for ima in nodulos:\n",
    "        if i==1:\n",
    "            imag=load_img(ima,color_mode=\"grayscale\")\n",
    "        else:\n",
    "            imag=load_img(ima,color_mode=\"grayscale\")\n",
    "        ancho,largo=imag.size\n",
    "        \n",
    "        plt.imshow(imag,cmap=\"gray\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        if ancho>450 or largo>450:\n",
    "            ratio=ancho/largo\n",
    "            if ratio>1:\n",
    "                imag=imag.resize((450,int(450/ratio)))\n",
    "\n",
    "            else:\n",
    "                imag=imag.resize((int(450*ratio),450))\n",
    "            ancho,largo=imag.size\n",
    "        imag=img_to_array(imag)/255.\n",
    "        imag=tf.image.pad_to_bounding_box(\n",
    "        imag, (tamaño-largo)//2,(tamaño-ancho)//2, 450, 450\n",
    "        )\n",
    "        imag=img_to_array(imag)\n",
    "        words=results_simple(imag,Inference_model)\n",
    "        \n",
    "        print(\"DESCRIPCIÓN:\\n\",words+\".\")\n",
    "        #print(\"Oval, circumscribed, isoechoic mass, with parallel orientation and no echogenic halo.\\nSuggestive of fibroadenoma. BIRADS® 3. Result predicted from dataset labels: benign.\")\n",
    "#         print(\"Irregular, spiculated, hipoechoic mass, with posterior shadowing, antiparallel orientation and echogenic halo.\\nBIRADS® 5. Result predicted from dataset labels: malignant.\")\n",
    "        #visualize(imagen=imag,alfas=np.array(alfas[:,0]))\n",
    "        i=i+1\n",
    "    if not nodulos:\n",
    "        print(\"Sin hallazgos. (BIRADS® 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f6caaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "with contextlib.redirect_stdout(None):\n",
    "    %cd yolov5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e46e548",
   "metadata": {},
   "source": [
    "# Esto es una prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4f98237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035f3232e8b64913846f94195983e0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Selecciona una ecografía'), FileUpload(value={}, description='Upload'), Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "benign(9).png\n"
     ]
    }
   ],
   "source": [
    "btn_upload = widgets.FileUpload()\n",
    "out_pl=widgets.Output()\n",
    "btn_run = widgets.Button(description='Descripción')\n",
    "lbl_pred = widgets.Label()\n",
    "def on_click_descripcion(change):\n",
    "    img=Image.open(io.BytesIO(btn_upload.data[-1]))\n",
    "    name=list(btn_upload.value.keys())[-1]\n",
    "    if \" \" in name:\n",
    "        name=\"\".join(name.split(\" \"))\n",
    "        name=re.sub(r\"[\\(\\)]\",'',name)\n",
    "    img_dir=os.path.join(\"../Imagenes_detect\",name)\n",
    "    img.save(img_dir)\n",
    "    out_pl.clear_output()\n",
    "    with out_pl: \n",
    "        display(img)\n",
    "        words=results(name,\"../Imagenes_detect\")\n",
    "btn_run.on_click(on_click_descripcion)\n",
    "VBox([widgets.Label('Selecciona una ecografía'), \n",
    "      btn_upload, btn_run, out_pl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "85d76b5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.7.13'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from platform import python_version\n",
    "python_version()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "YOLO_tf",
   "language": "python",
   "name": "yolo_tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
